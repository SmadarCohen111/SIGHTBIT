{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIGHTBIT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnKLZmm9iQ/+6lUi05Kl6E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SmadarCohen111/SIGHTBIT/blob/main/SIGHTBIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FDEConkBeIj"
      },
      "source": [
        "**Environment installation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc8dlbDwBdwF"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "# workaround: install old version of pytorch since detectron2 hasn't released packages for pytorch 1.9 (issue: https://github.com/facebookresearch/detectron2/issues/3158)\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install detectron2 that matches pytorch 1.8\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime\n",
        "!pip install numpyencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyqC4flGBj26"
      },
      "source": [
        "**import and check pytorch version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvgwAQ60BZGi"
      },
      "source": [
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "assert torch.__version__.startswith(\"1.8\")   # please manually install torch 1.8 if Colab changes its default version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70Hw_ds7BwzM"
      },
      "source": [
        "**import libraries and utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlJfMkUcBsL1"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "from numpyencoder import NumpyEncoder\n",
        "import scipy.misc\n",
        "import os, json, cv2, random\n",
        "import requests\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCPPujBbCNvD"
      },
      "source": [
        "**Mount drive for saving new dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBqkGDkHCRt9"
      },
      "source": [
        "#click the link, copy the gauth and paste it here\n",
        " \n",
        "drive.mount ('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXA-54v5CaDI"
      },
      "source": [
        "**Help methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0tm5PzZCV-X"
      },
      "source": [
        "#remove outlairs\n",
        "\n",
        "def reject_outliers(data, m=2):\n",
        "    return data[abs(data - np.mean(data)) < m * np.std(data)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKQC-WdWCV6n"
      },
      "source": [
        "def get_max_width_height(mask_idxs):\n",
        "  widths = np.array([w for w,h in mask_idxs])\n",
        "  widths = reject_outliers(widths)\n",
        "  height = np.array([h for h,w in mask_idxs])\n",
        "  height = reject_outliers(height)\n",
        "  return max(widths), max(height)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhJMCXDWCV3k"
      },
      "source": [
        "#load json file\n",
        "\n",
        "def resolve_json(zip_path):\n",
        "  with open(zip_path, 'r') as f:\n",
        "    fileJson = json.load(f)\n",
        "  return fileJson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd2PZQjGCV0d"
      },
      "source": [
        "def modify_categories_data(categories,category_id):\n",
        "    for i in categories:\n",
        "      if(i['id'] == category_id):\n",
        "        new_categories = i\n",
        "    return new_categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu_t7sdTCVwd"
      },
      "source": [
        "def modify_annotations_data(annotations, categories, image_id):\n",
        "  for i in annotations:  \n",
        "    if i['image_id'] == image_id:\n",
        "      new_annotation = i\n",
        "      list_categories = modify_categories_data(categories, i['category_id'])\n",
        "  return new_annotation, list_categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mj3IBArCVtT"
      },
      "source": [
        "def modify_images_data(images, image_id, width, height):\n",
        "  for img in images:\n",
        "    if img['id'] == image_id:\n",
        "       img['height'] = height \n",
        "       img['width']= width \n",
        "       image_data = img\n",
        "  return image_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrUd0Zx1CVqN"
      },
      "source": [
        "# export the data to json file\n",
        "\n",
        "def create_json_file(annotations_lists):\n",
        "  with open(\"my.json\",\"w\") as f:\n",
        "      json.dump(annotations_lists,f, indent=4, cls=NumpyEncoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2flBQBYCVZD"
      },
      "source": [
        "# build dict for the new info of the cropped images\n",
        "\n",
        "def build_dict(train_json, image_id, new_width,new_height):\n",
        "\n",
        "  images_dict = modify_images_data(train_json['images'], image_id, new_width, new_height)\n",
        "  annotation_dict, categories_dict = modify_annotations_data(train_json['annotations'], train_json['categories'], image_id)\n",
        "  \n",
        "  images_list.append(images_dict)\n",
        "  annotation_list.append(annotation_dict)\n",
        "  categories_list.append(categories_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71W6ZZTmCu_5"
      },
      "source": [
        "#crop the original image and calculate the new img info\n",
        "\n",
        "def image_cropper(im, image_id, outputs, sky_id, width, height,images_list, annotation_list, categories_list, counter_img, train_json):\n",
        " \n",
        "  pan_array = outputs['panoptic_seg'][0]\n",
        "  sky_px = np.argwhere((pan_array.cpu().numpy() == sky_id ))\n",
        "\n",
        "  max_width, max_height = get_max_width_height(sky_px)\n",
        "  new_width = abs(width - max_width)\n",
        "  new_height = abs(height - max_height)\n",
        "  \n",
        "  build_dict(train_json, image_id, new_width,new_height )\n",
        "\n",
        "  cropped_img = im[max_width:, max_height:, :]\n",
        "    \n",
        "  a = cv2.imwrite('/content/drive/MyDrive/cropped_images/{}.jpg'.format(counter_img), cropped_img)\n",
        "  print(\"cropped image - \")\n",
        "  cv2_imshow(cropped_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7MASxErCyBS"
      },
      "source": [
        "**Image prediction, segementation and filter the images without the sky area**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mBq2bXgCu7r"
      },
      "source": [
        "# image prediction, segementation and filter the images without the sky area\n",
        "\n",
        "def pred_images(im, image_id, width, height, counter_img, training_number, images_list, annotation_list, categories_list, train_json ):\n",
        "  \n",
        "  print(\"origianl image - \")\n",
        "  cv2_imshow(im)\n",
        "  outputs = predictor(im)\n",
        "  segements_info = outputs[\"panoptic_seg\"][1]\n",
        "  \n",
        "  sky_id = 0\n",
        "  for sgmnt_info in segements_info:\n",
        "    if (sgmnt_info['category_id'] == 40):\n",
        "      sky_id = sgmnt_info['id']\n",
        "\n",
        "  if(sky_id != 0):\n",
        "    image_cropper(im,image_id, outputs, sky_id, width, height,images_list, annotation_list, categories_list, counter_img, train_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmt3XF37C212"
      },
      "source": [
        "**extarcting the image and the data about the image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXWwXLADCu4R"
      },
      "source": [
        "# extarcting the image and the data about the image\n",
        "\n",
        "def extract_imgs_and_info(image_id, training_number, images_list, annotation_list, categories_list,counter_img, train_json):\n",
        "    \n",
        "  for ix, image in enumerate(train_json['images']):\n",
        "      if(image['id'] != image_id):\n",
        "        continue\n",
        "      else:\n",
        "        width = image['width']\n",
        "        height = image['height']\n",
        "        img = train_json['images'][ix]\n",
        "        r = requests.get(img['coco_url'], allow_redirects=True)\n",
        "        img_path = ''.join([save_dir, '/', img['file_name']])\n",
        "        \n",
        "        with open(img_path, 'wb') as f:\n",
        "          # Read Image as np array from url\n",
        "          arr = np.asarray(bytearray(r.content), dtype=np.uint8)\n",
        "          np_img = cv2.imdecode(arr, -1)\n",
        "          pred_images(np_img, image_id, width, height, counter_img, training_number, images_list, annotation_list, categories_list, train_json)\n",
        "          counter_img += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1FsMFqXCutY"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  \n",
        "  #`initialize Configuration and predictor`\n",
        "  cfg = get_cfg()\n",
        "  cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
        "  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
        "  predictor = DefaultPredictor(cfg)\n",
        "  \n",
        "  #Obtaining dataset\n",
        "  #commaned those lines after the first run\n",
        "  !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "  !unzip annotations_trainval2017.zip\n",
        "  \n",
        "  #directory for saving images\n",
        "  path = \"/content/drive/MyDrive/cropped_images\"\n",
        "  if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "  !mkdir get_images\n",
        "  save_dir = 'get_images'\n",
        "\n",
        "  #help vars\n",
        "  \n",
        "  #choose the number of samples you would like to train \n",
        "  training_number = 2\n",
        "  #max images is counter\n",
        "  max_images=0\n",
        "  images_list = [] \n",
        "  annotation_list = [] \n",
        "  categories_list = []\n",
        "\n",
        "  train_json = resolve_json('./annotations/instances_val2017.json')\n",
        "\n",
        "  #itrate throgh the dataset\n",
        "  for ix, imag in enumerate(train_json['annotations']):\n",
        "      if(imag['category_id'] == 5):\n",
        "        max_images += 1\n",
        "        extract_imgs_and_info(imag['image_id'], training_number, images_list, annotation_list, categories_list,max_images, train_json)\n",
        "        if max_images > training_number:\n",
        "            break\n",
        "\n",
        "  annotations_lists = {\"image\": images_list,\"annotation\": annotation_list,\"categories\": categories_list }\n",
        "  create_json_file(annotations_lists)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}